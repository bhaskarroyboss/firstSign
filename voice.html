<!DOCTYPE html>
<html lang="en" >
<head>
  <meta charset="UTF-8" />
  <title>Voice Baseline - Improved</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-100 flex flex-col items-center justify-center min-h-screen p-6">

  <div class="bg-white rounded-2xl shadow-xl p-8 w-full max-w-lg text-center">
      <img src="logo.jpg" alt="Stroke Detection Logo" class="h-16 mx-auto" />
    <h1 class="text-2xl font-bold mb-6">Record Your Normal Voice</h1>
    <p class="mb-6">Please say the following phrase clearly:</p>
    <p class="mb-6 text-indigo-700 font-semibold text-lg">"I am feeling fine today"</p>

    <button id="startBtn" class="bg-blue-600 text-white px-6 py-2 rounded-xl hover:bg-blue-700 transition mb-6">
      Start Recording
    </button>

    <p id="status" class="text-gray-700 mb-4"></p>

    <p><strong>Transcript:</strong> <span id="transcript"></span></p>

    <button id="nextBtn" disabled class="bg-green-600 text-white px-6 py-2 rounded-xl hover:bg-green-700 transition mt-6">
      Next
    </button>
  </div>

<script>
  const phrase = "I am feeling fine today";
  const startBtn = document.getElementById('startBtn');
  const status = document.getElementById('status');
  const transcriptElem = document.getElementById('transcript');
  const nextBtn = document.getElementById('nextBtn');

  let recognition;
  let startTime, endTime;

  function levenshtein(a, b) {
    const dp = Array.from({length: a.length + 1}, () => Array(b.length + 1).fill(0));
    for(let i = 0; i <= a.length; i++) dp[i][0] = i;
    for(let j = 0; j <= b.length; j++) dp[0][j] = j;

    for(let i = 1; i <= a.length; i++) {
      for(let j = 1; j <= b.length; j++) {
        if(a[i-1] === b[j-1]) dp[i][j] = dp[i-1][j-1];
        else dp[i][j] = 1 + Math.min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]);
      }
    }
    return dp[a.length][b.length];
  }

  startBtn.addEventListener('click', () => {
    if (!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) {
      alert('Speech Recognition API not supported in this browser.');
      return;
    }

    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = 'en-US';
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;

    startBtn.disabled = true;
    transcriptElem.textContent = '';
    status.textContent = 'Listening... Please say: "' + phrase + '"';
    startTime = performance.now();

    recognition.start();

    recognition.onresult = (event) => {
      endTime = performance.now();
      const spokenText = event.results[0][0].transcript.trim();
      const confidence = event.results[0][0].confidence;

      transcriptElem.textContent = spokenText + ` (Confidence: ${(confidence*100).toFixed(1)}%)`;

      // Calculate Levenshtein distance normalized similarity
      const dist = levenshtein(spokenText.toLowerCase(), phrase.toLowerCase());
      const maxLen = Math.max(spokenText.length, phrase.length);
      const similarity = ((maxLen - dist) / maxLen) * 100;

      // Calculate speech duration (in seconds)
      const duration = (endTime - startTime) / 1000;

      // Store baseline voice data: transcript, similarity, confidence, duration
      const baselineVoiceData = {
        transcript: spokenText,
        similarity: similarity.toFixed(2),
        confidence: confidence.toFixed(2),
        duration: duration.toFixed(2)
      };

      localStorage.setItem('voiceBaseline', JSON.stringify(baselineVoiceData));
      status.textContent = `Recording saved! Similarity: ${similarity.toFixed(2)}%, Duration: ${duration.toFixed(2)}s`;

      nextBtn.disabled = false;
    };

    recognition.onerror = (event) => {
      status.textContent = 'Error: ' + event.error;
      startBtn.disabled = false;
    };
  });

  nextBtn.addEventListener('click', () => {
    window.location.href = 'accelerometer.html'; // next step
  });
</script>

</body>
</html>
